from core import BaseTool, ToolMetadata, ToolResult
from typing import Dict, Any, Optional, List, Union
import logging
import os
from pathlib import Path
from openai import OpenAI
import openai
import re
from dotenv import load_dotenv
import time

# å¤šè¯­è¨€æ”¯æŒçš„ç« èŠ‚æ ‡é¢˜é…ç½®
SECTION_HEADERS = {
    "English": {
        "motivation": "Motivation of the study",
        "methodology": "Methodology or strategy", 
        "contributions": "Key contributions",
        "challenges": "Limitations or challenges"
    },
    "Chinese": {
        "motivation": "ç ”ç©¶åŠ¨æœº",
        "methodology": "æ–¹æ³•æˆ–ç­–ç•¥",
        "contributions": "ä¸»è¦è´¡çŒ®", 
        "challenges": "æŒ‘æˆ˜æˆ–å±€é™"
    }
}

class LLMPaperSummarizerTool(BaseTool):
    """
    åŸºäºLLMçš„è®ºæ–‡æ€»ç»“å·¥å…· - ä½¿ç”¨OpenAI Assistant APIç›´æ¥å¤„ç†PDFæ–‡ä»¶
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. ç›´æ¥ä¸Šä¼ PDFæ–‡ä»¶åˆ°OpenAIè¿›è¡Œå¤„ç†
    2. åˆ©ç”¨GPT-4oçš„å¼ºå¤§ç†è§£èƒ½åŠ›åˆ†æè®ºæ–‡å†…å®¹
    3. ç”Ÿæˆç»“æ„åŒ–çš„è®ºæ–‡æ€»ç»“ï¼ˆåŠ¨æœºã€æ–¹æ³•ã€è´¡çŒ®ã€æŒ‘æˆ˜ï¼‰
    4. æ”¯æŒå¤šè¯­è¨€è¾“å‡ºï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰
    5. è‡ªåŠ¨ç®¡ç†OpenAI Assistantå®ä¾‹
    
    ä¼˜åŠ¿ï¼š
    - æ— éœ€å¤æ‚çš„PDFæ–‡æœ¬æå–é€»è¾‘
    - èƒ½å¤Ÿç†è§£å›¾è¡¨ã€å…¬å¼ç­‰å¤æ‚å†…å®¹
    - æä¾›é«˜è´¨é‡çš„ç»“æ„åŒ–æ€»ç»“
    - æ”¯æŒå¤§æ–‡ä»¶å¤„ç†
    - å‡å°‘æœ¬åœ°ä¾èµ–å’Œç»´æŠ¤æˆæœ¬
    
    é€‚ç”¨åœºæ™¯ï¼š
    - å­¦æœ¯è®ºæ–‡å¿«é€Ÿæ€»ç»“
    - ç ”ç©¶æ–‡çŒ®æ‰¹é‡å¤„ç†
    - å¤šè¯­è¨€è®ºæ–‡åˆ†æ
    - ç»“æ„åŒ–ä¿¡æ¯æå–
    """
    
    def __init__(self, log_queue=None):
        """
        åˆå§‹åŒ–LLMè®ºæ–‡æ€»ç»“å·¥å…·
        
        å‚æ•°:
            log_queue: æ—¥å¿—é˜Ÿåˆ—ï¼Œç”¨äºå‘ä¸»è¿›ç¨‹å‘é€æ—¥å¿—ä¿¡æ¯
        
        åˆå§‹åŒ–å†…å®¹:
        1. è®¾ç½®OpenAIå®¢æˆ·ç«¯é…ç½®
        2. å®šä¹‰æ”¯æŒçš„æ–‡ä»¶æ ¼å¼å’Œå¤§å°é™åˆ¶
        3. é…ç½®Assistantå‚æ•°
        4. è®¾ç½®å¤šè¯­è¨€æ”¯æŒ
        5. åˆå§‹åŒ–ç¼“å­˜å’Œé”™è¯¯å¤„ç†æœºåˆ¶
        6. ä».envæ–‡ä»¶åŠ è½½APIå¯†é’¥
        """
        super().__init__(log_queue)
        
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # ===========================================
        # OpenAI API é…ç½®
        # ===========================================
        self.api_key = os.getenv('OPENAI_API_KEY')  # ä».envæ–‡ä»¶è¯»å–APIå¯†é’¥
        self.client = None  # OpenAIå®¢æˆ·ç«¯å®ä¾‹ï¼Œåœ¨validate_parametersä¸­åˆå§‹åŒ–
        self.assistant_id = None  # Assistant IDï¼Œå»¶è¿Ÿåˆå§‹åŒ–
        self.default_model = "gpt-4o"  # é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹
        self.default_temperature = 0.1  # é»˜è®¤æ¸©åº¦å‚æ•°ï¼Œç¡®ä¿è¾“å‡ºç¨³å®šæ€§
        
        # ===========================================
        # æ–‡ä»¶å¤„ç†é…ç½®
        # ===========================================
        self.supported_formats = ['.pdf']  # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        self.max_file_size = 100 * 1024 * 1024  # æœ€å¤§æ–‡ä»¶å¤§å°ï¼š100MB
        self.min_file_size = 1024  # æœ€å°æ–‡ä»¶å¤§å°ï¼š1KB
        
        # ===========================================
        # æ€»ç»“é…ç½®
        # ===========================================
        self.supported_languages = ['Chinese', 'English']  # æ”¯æŒçš„è¾“å‡ºè¯­è¨€
        self.default_language = 'English'  # é»˜è®¤è¾“å‡ºè¯­è¨€
        self.assistant_name = "Academic Paper Summarizer"  # Assistantåç§°
        
        # ===========================================
        # ç¼“å­˜å’Œæ€§èƒ½é…ç½®
        # ===========================================
        self.enable_caching = True  # æ˜¯å¦å¯ç”¨ç»“æœç¼“å­˜
        self.cache_duration = 3600  # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
        self.max_retries = 3  # APIè°ƒç”¨æœ€å¤§é‡è¯•æ¬¡æ•°
        self.retry_delay = 1  # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
    
    def get_metadata(self) -> ToolMetadata:
        """
        è·å–å·¥å…·çš„å…ƒæ•°æ®ä¿¡æ¯
        
        è¿”å›å·¥å…·çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
        1. å·¥å…·åç§°å’Œæè¿°
        2. è¾“å…¥å‚æ•°å®šä¹‰å’ŒéªŒè¯è§„åˆ™
        3. è¾“å‡ºæ ¼å¼è¯´æ˜
        4. ä½¿ç”¨ç¤ºä¾‹å’Œæ³¨æ„äº‹é¡¹
        
        è¿”å›:
            ToolMetadata: åŒ…å«å®Œæ•´å·¥å…·ä¿¡æ¯çš„å…ƒæ•°æ®å¯¹è±¡
        
        å‚æ•°å®šä¹‰:
        - pdf_path (str, å¿…éœ€): PDFæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        - title (str, å¯é€‰): è®ºæ–‡æ ‡é¢˜ï¼Œç”¨äºè¡¥å……ä¸Šä¸‹æ–‡
        - abstract (str, å¯é€‰): è®ºæ–‡æ‘˜è¦ï¼Œç”¨äºè¡¥å……ä¸Šä¸‹æ–‡
        - language (str, å¯é€‰): è¾“å‡ºè¯­è¨€ï¼Œé»˜è®¤'English'
        - model (str, å¯é€‰): ä½¿ç”¨çš„OpenAIæ¨¡å‹ï¼Œé»˜è®¤'gpt-4o'
        - temperature (float, å¯é€‰): æ¨¡å‹æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤0.1
        
        æ³¨æ„: OpenAI APIå¯†é’¥ä».envæ–‡ä»¶ä¸­çš„OPENAI_API_KEYå˜é‡è‡ªåŠ¨è¯»å–
        """
        return ToolMetadata(
            # ===========================================
            # å¿…éœ€å±æ€§ - å·¥å…·åŸºæœ¬ä¿¡æ¯
            # ===========================================
            name="llm_paper_summarizer",
            description=(
                "åŸºäºOpenAI Assistant APIçš„æ™ºèƒ½è®ºæ–‡æ€»ç»“å·¥å…·ã€‚"
                "ç›´æ¥ä¸Šä¼ PDFæ–‡ä»¶åˆ°OpenAIè¿›è¡Œå¤„ç†ï¼Œåˆ©ç”¨GPT-4oçš„å¼ºå¤§ç†è§£èƒ½åŠ›åˆ†æè®ºæ–‡å†…å®¹ï¼Œ"
                "ç”ŸæˆåŒ…å«ç ”ç©¶åŠ¨æœºã€æ–¹æ³•ç­–ç•¥ã€ä¸»è¦è´¡çŒ®ã€æŒ‘æˆ˜å±€é™å››ä¸ªéƒ¨åˆ†çš„ç»“æ„åŒ–æ€»ç»“ã€‚"
                "æ”¯æŒä¸­è‹±æ–‡è¾“å‡ºï¼Œæ— éœ€å¤æ‚çš„æœ¬åœ°PDFè§£æï¼Œèƒ½å¤Ÿç†è§£å›¾è¡¨ã€å…¬å¼ç­‰å¤æ‚å†…å®¹ã€‚"
            ),
            
            # ===========================================
            # å‚æ•°å®šä¹‰ - è¯¦ç»†çš„è¾“å…¥å‚æ•°è§„èŒƒ
            # ===========================================
            parameters={
                "pdf_path": {
                    "type": "str",
                    "required": True,
                    "description": "PDFæ–‡ä»¶çš„å®Œæ•´ç»å¯¹è·¯å¾„",
                    "validation": {
                        "format": "file_path",
                        "extensions": [".pdf"],
                        "must_exist": True
                    },
                    "example": "C:/papers/research_paper.pdf"
                },
                "title": {
                    "type": "str",
                    "required": False,
                    "description": "è®ºæ–‡æ ‡é¢˜ï¼Œç”¨äºæä¾›é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¸®åŠ©AIæ›´å¥½åœ°ç†è§£è®ºæ–‡ä¸»é¢˜",
                    "validation": {
                        "max_length": 500,
                        "min_length": 1
                    },
                    "example": "Deep Learning for Natural Language Processing: A Survey"
                },
                "abstract": {
                    "type": "str",
                    "required": False,
                    "description": "è®ºæ–‡æ‘˜è¦ï¼Œç”¨äºæä¾›è®ºæ–‡æ¦‚è¦ä¿¡æ¯ï¼Œè¾…åŠ©AIç†è§£è®ºæ–‡æ ¸å¿ƒå†…å®¹",
                    "validation": {
                        "max_length": 2000,
                        "min_length": 10
                    },
                    "example": "This paper presents a comprehensive survey of deep learning techniques..."
                },
                "language": {
                    "type": "str",
                    "required": False,
                    "default": "English",
                    "description": "è¾“å‡ºæ€»ç»“çš„è¯­è¨€ï¼Œæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡",
                    "validation": {
                        "enum": ["Chinese", "English"]
                    },
                    "example": "English"
                },
                "model": {
                    "type": "str",
                    "required": False,
                    "default": "gpt-4o",
                    "description": "ä½¿ç”¨çš„OpenAIæ¨¡å‹ï¼Œæ¨èä½¿ç”¨gpt-4oä»¥è·å¾—æœ€ä½³æ•ˆæœ",
                    "validation": {
                        "enum": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"]
                    },
                    "example": "gpt-4o"
                },
                "temperature": {
                    "type": "float",
                    "required": False,
                    "default": 0.1,
                    "description": "æ¨¡å‹åˆ›é€ æ€§å‚æ•°ï¼Œè¾ƒä½å€¼ç¡®ä¿è¾“å‡ºç¨³å®šæ€§ï¼Œè¾ƒé«˜å€¼å¢åŠ åˆ›é€ æ€§",
                    "validation": {
                        "min": 0.0,
                        "max": 2.0
                    },
                    "example": 0.1
                }
            },
            
            # ===========================================
            # è¿”å›å€¼ç±»å‹å’Œåˆ†ç±»ä¿¡æ¯
            # ===========================================
            return_type="dict",
            category="analysis",
            
            # ===========================================
            # è¯¦ç»†çš„è¿”å›å€¼ç»“æ„æè¿°
            # ===========================================
            return_description={
                "schema": {
                    "type": "object",
                    "properties": {
                        "success": {
                            "type": "boolean",
                            "description": "æ“ä½œæ˜¯å¦æˆåŠŸå®Œæˆ"
                        },
                        "summary": {
                            "type": "object",
                            "description": "ç»“æ„åŒ–çš„è®ºæ–‡æ€»ç»“å†…å®¹",
                            "properties": {
                                "motivation": {
                                    "type": "string",
                                    "description": "ç ”ç©¶åŠ¨æœº - è®ºæ–‡è¦è§£å†³çš„é—®é¢˜å’Œç ”ç©¶èƒŒæ™¯"
                                },
                                "methodology": {
                                    "type": "string",
                                    "description": "æ–¹æ³•ç­–ç•¥ - è®ºæ–‡é‡‡ç”¨çš„ç ”ç©¶æ–¹æ³•å’ŒæŠ€æœ¯è·¯çº¿"
                                },
                                "contributions": {
                                    "type": "string",
                                    "description": "ä¸»è¦è´¡çŒ® - è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°ç‚¹å’Œå­¦æœ¯ä»·å€¼"
                                },
                                "challenges": {
                                    "type": "string",
                                    "description": "æŒ‘æˆ˜å±€é™ - è®ºæ–‡å­˜åœ¨çš„é—®é¢˜ã€å±€é™æ€§å’Œæœªæ¥å·¥ä½œæ–¹å‘"
                                }
                            },
                            "required": ["motivation", "methodology", "contributions", "challenges"]
                        },
                        "metadata": {
                            "type": "object",
                            "description": "å¤„ç†è¿‡ç¨‹çš„å…ƒæ•°æ®ä¿¡æ¯",
                            "properties": {
                                "model_used": {
                                    "type": "string",
                                    "description": "å®é™…ä½¿ç”¨çš„OpenAIæ¨¡å‹"
                                },
                                "processing_time": {
                                    "type": "number",
                                    "description": "å¤„ç†è€—æ—¶ï¼ˆç§’ï¼‰"
                                },
                                "file_size": {
                                    "type": "integer",
                                    "description": "PDFæ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰"
                                },
                                "language": {
                                    "type": "string",
                                    "description": "è¾“å‡ºè¯­è¨€"
                                }
                            }
                        },
                        "raw_response": {
                            "type": "string",
                            "description": "OpenAI Assistantçš„åŸå§‹å“åº”æ–‡æœ¬ï¼Œç”¨äºè°ƒè¯•å’Œè¿›ä¸€æ­¥å¤„ç†"
                        },
                        "error": {
                            "type": "string",
                            "description": "é”™è¯¯ä¿¡æ¯ï¼ˆä»…åœ¨successä¸ºfalseæ—¶å­˜åœ¨ï¼‰"
                        }
                    },
                    "required": ["success"]
                },
                "examples": {
                    "success_case": {
                        "success": True,
                        "summary": {
                            "motivation": "æœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ä¼ ç»Ÿè‡ªç„¶è¯­è¨€å¤„ç†æ–¹æ³•åœ¨å¤„ç†å¤æ‚è¯­ä¹‰ç†è§£ä»»åŠ¡ä¸­çš„å±€é™æ€§...",
                            "methodology": "è®ºæ–‡é‡‡ç”¨äº†åŸºäºTransformeræ¶æ„çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç»“åˆæ³¨æ„åŠ›æœºåˆ¶...",
                            "contributions": "ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼š1ï¼‰æå‡ºäº†æ–°çš„é¢„è®­ç»ƒç­–ç•¥ï¼›2ï¼‰åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½...",
                            "challenges": "è®ºæ–‡çš„å±€é™æ€§ä¸»è¦ä½“ç°åœ¨è®¡ç®—èµ„æºéœ€æ±‚è¾ƒé«˜ï¼Œå¯¹å°æ ·æœ¬æ•°æ®çš„å¤„ç†èƒ½åŠ›æœ‰å¾…æå‡..."
                        },
                        "metadata": {
                            "model_used": "gpt-4o",
                            "processing_time": 45.2,
                            "file_size": 2048576,
                            "language": "Chinese"
                        }
                    },
                    "error_case": {
                        "success": False,
                        "error": "PDFæ–‡ä»¶æ— æ³•è¯»å–æˆ–æ ¼å¼ä¸æ”¯æŒ"
                    }
                }
            },
            
            # ===========================================
            # å¯é€‰å±æ€§ - æ ‡ç­¾å’Œç‰ˆæœ¬ä¿¡æ¯
            # ===========================================
            tags=["pdf", "summarization", "academic", "openai", "llm", "research"],
            version="1.0.0"
        )
    
    def validate_parameters(self, **kwargs) -> bool:
        """
        éªŒè¯è¾“å…¥å‚æ•°çš„æœ‰æ•ˆæ€§
        
        éªŒè¯å†…å®¹:
        1. å¿…éœ€å‚æ•°æ£€æŸ¥ï¼ˆpdf_pathï¼‰
        2. æ–‡ä»¶å­˜åœ¨æ€§å’Œæ ¼å¼éªŒè¯
        3. APIå¯†é’¥å­˜åœ¨æ€§éªŒè¯ï¼ˆä»ç¯å¢ƒå˜é‡ï¼‰
        4. å¯é€‰å‚æ•°ç±»å‹å’ŒèŒƒå›´éªŒè¯
        5. OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–
        
        å‚æ•°:
            pdf_path (str): PDFæ–‡ä»¶è·¯å¾„
            title (str, optional): è®ºæ–‡æ ‡é¢˜
            abstract (str, optional): è®ºæ–‡æ‘˜è¦
            language (str, optional): è¾“å‡ºè¯­è¨€
            model (str, optional): OpenAIæ¨¡å‹åç§°
            temperature (float, optional): æ¨¡å‹æ¸©åº¦å‚æ•°
        
        è¿”å›:
            bool: éªŒè¯æ˜¯å¦é€šè¿‡
        
        éªŒè¯è§„åˆ™:
        - pdf_path: å¿…é¡»æ˜¯å­˜åœ¨çš„.pdfæ–‡ä»¶
        - api_key: ä»ç¯å¢ƒå˜é‡OPENAI_API_KEYè‡ªåŠ¨è·å–ï¼Œå¿…é¡»å­˜åœ¨ä¸”æ ¼å¼æœ‰æ•ˆ
        - language: å¿…é¡»åœ¨æ”¯æŒçš„è¯­è¨€åˆ—è¡¨ä¸­
        - model: å¿…é¡»æ˜¯OpenAIæ”¯æŒçš„æ¨¡å‹åç§°
        - temperature: å¿…é¡»åœ¨0.0-2.0èŒƒå›´å†…
        """
        try:
            # ===========================================
            # 1. æ£€æŸ¥å¿…éœ€å‚æ•° - pdf_path
            # ===========================================
            pdf_path = kwargs.get('pdf_path')
            if not pdf_path:
                if self.log_queue:
                    self.log_queue.put("é”™è¯¯: ç¼ºå°‘å¿…éœ€å‚æ•°: pdf_path")
                return False
            
            if not isinstance(pdf_path, str):
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: pdf_pathå¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå½“å‰ç±»å‹: {type(pdf_path)}")
                return False
            
            # ===========================================
            # 2. éªŒè¯PDFæ–‡ä»¶è·¯å¾„ã€å­˜åœ¨æ€§ã€æ ¼å¼
            # ===========================================
            pdf_file = Path(pdf_path)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not pdf_file.exists():
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
                return False
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶ï¼ˆä¸æ˜¯ç›®å½•ï¼‰
            if not pdf_file.is_file():
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {pdf_path}")
                return False
            
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            if pdf_file.suffix.lower() != '.pdf':
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: æ–‡ä»¶å¿…é¡»æ˜¯PDFæ ¼å¼ï¼Œå½“å‰æ ¼å¼: {pdf_file.suffix}")
                return False
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»
            try:
                with open(pdf_path, 'rb') as f:
                    f.read(1)  # å°è¯•è¯»å–1å­—èŠ‚
            except (IOError, OSError) as e:
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: æ— æ³•è¯»å–PDFæ–‡ä»¶: {e}")
                return False
            
            
            # ===========================================
            # 4. éªŒè¯å¯é€‰å‚æ•° - title
            # ===========================================
            title = kwargs.get('title')
            if title is not None:
                if not isinstance(title, str):
                    if self.log_queue:
                        self.log_queue.put(f"é”™è¯¯: titleå¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå½“å‰ç±»å‹: {type(title)}")
                    return False
                
                if len(title.strip()) == 0:
                    if self.log_queue:
                        self.log_queue.put("é”™è¯¯: titleä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²")
                    return False
                
                if len(title) > 500:
                    if self.log_queue:
                        self.log_queue.put(f"é”™è¯¯: titleé•¿åº¦ä¸èƒ½è¶…è¿‡500å­—ç¬¦ï¼Œå½“å‰é•¿åº¦: {len(title)}")
                    return False
            
            # ===========================================
            # 5. éªŒè¯å¯é€‰å‚æ•° - abstract
            # ===========================================
            abstract = kwargs.get('abstract')
            if abstract is not None:
                if not isinstance(abstract, str):
                    if self.log_queue:
                        self.log_queue.put(f"é”™è¯¯: abstractå¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå½“å‰ç±»å‹: {type(abstract)}")
                    return False
                
            
            # ===========================================
            # 6. éªŒè¯å¯é€‰å‚æ•° - language
            # ===========================================
            language = kwargs.get('language', 'English')
            if not isinstance(language, str):
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: languageå¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå½“å‰ç±»å‹: {type(language)}")
                return False
            
            if language not in self.supported_languages:
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: ä¸æ”¯æŒçš„è¯­è¨€: {language}ï¼Œæ”¯æŒçš„è¯­è¨€: {self.supported_languages}")
                return False
            
            # ===========================================
            # 7. éªŒè¯å¯é€‰å‚æ•° - model
            # ===========================================
            model = kwargs.get('model', self.default_model)
            if not isinstance(model, str):
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: modelå¿…é¡»æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå½“å‰ç±»å‹: {type(model)}")
                return False
            
            supported_models = ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo"]
            if model not in supported_models:
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: ä¸æ”¯æŒçš„æ¨¡å‹: {model}ï¼Œæ”¯æŒçš„æ¨¡å‹: {supported_models}")
                return False
            
            # ===========================================
            # 8. éªŒè¯å¯é€‰å‚æ•° - temperature
            # ===========================================
            temperature = kwargs.get('temperature', self.default_temperature)
            if not isinstance(temperature, (int, float)):
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: temperatureå¿…é¡»æ˜¯æ•°å­—ç±»å‹ï¼Œå½“å‰ç±»å‹: {type(temperature)}")
                return False
            
            if not (0.0 <= temperature <= 2.0):
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: temperatureå¿…é¡»åœ¨0.0-2.0èŒƒå›´å†…ï¼Œå½“å‰å€¼: {temperature}")
                return False
            
            # ===========================================
            # 10. è®°å½•éªŒè¯æˆåŠŸä¿¡æ¯
            # ===========================================
            if self.log_queue:
                self.log_queue.put(f"å‚æ•°éªŒè¯æˆåŠŸ - æ–‡ä»¶: {pdf_path}, è¯­è¨€: {language}, æ¨¡å‹: {model}")
            return True
            
        except Exception as e:
            if self.log_queue:
                self.log_queue.put(f"é”™è¯¯: å‚æ•°éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            return False
    
    def is_available(self) -> bool:
        """
        æ£€æŸ¥å·¥å…·çš„å¯ç”¨æ€§
        
        åœ¨å·¥å…·æ³¨å†Œæ—¶æ‰§è¡Œä¸€æ¬¡æ€§æ£€æŸ¥ï¼Œç¡®ä¿å·¥å…·å¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚
        è¿™æ ·é¿å…äº†åœ¨æ¯æ¬¡å¤„ç†æ•°æ®æ—¶é‡å¤éªŒè¯ï¼Œæé«˜äº†æ‰§è¡Œæ•ˆç‡ã€‚
        
        æ£€æŸ¥å†…å®¹:
        1. OpenAIåº“æ˜¯å¦æ­£ç¡®å®‰è£…å’Œå¯¼å…¥
        2. APIå¯†é’¥æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æœ‰æ•ˆ
        3. OpenAIå®¢æˆ·ç«¯æ˜¯å¦èƒ½æˆåŠŸåˆå§‹åŒ–
        4. åŸºæœ¬çš„ç³»ç»Ÿä¾èµ–æ˜¯å¦æ»¡è¶³
        
        è¿”å›:
            bool: å·¥å…·æ˜¯å¦å¯ç”¨
        
        æ³¨æ„:
        - æ­¤å‡½æ•°åœ¨å·¥å…·æ³¨å†Œæ—¶è°ƒç”¨ï¼Œä¸åœ¨æ¯æ¬¡æ•°æ®å¤„ç†æ—¶è°ƒç”¨
        - APIå¯†é’¥éªŒè¯å’Œå®¢æˆ·ç«¯åˆå§‹åŒ–éƒ½åœ¨è¿™é‡Œå®Œæˆ
        - å¦‚æœéªŒè¯å¤±è´¥ï¼Œå·¥å…·å°†ä¸ä¼šè¢«æ³¨å†Œåˆ°ç³»ç»Ÿä¸­
        """
        try:
            # ===========================================
            # 1. æ£€æŸ¥OpenAIåº“æ˜¯å¦æ­£ç¡®å®‰è£…
            # ===========================================
            try:
                from openai import OpenAI
                import openai
                # æ£€æŸ¥openaiåº“ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
                if hasattr(openai, '__version__'):
                    if self.log_queue:
                        self.log_queue.put(f"OpenAIåº“ç‰ˆæœ¬: {openai.__version__}")
            except ImportError as e:
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: OpenAIåº“æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥: {e}")
                return False
            
            # ===========================================
            # 2. éªŒè¯APIå¯†é’¥å­˜åœ¨æ€§å’Œæ ¼å¼
            # ===========================================
            if not self.api_key:
                if self.log_queue:
                    self.log_queue.put("é”™è¯¯: æœªæ‰¾åˆ°OpenAI APIå¯†é’¥ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEY")
                return False
            
            # éªŒè¯APIå¯†é’¥æ ¼å¼ï¼ˆOpenAIå¯†é’¥é€šå¸¸ä»¥sk-å¼€å¤´ï¼‰
            if not self.api_key.startswith('sk-'):
                if self.log_queue:
                    self.log_queue.put("é”™è¯¯: OpenAI APIå¯†é’¥æ ¼å¼æ— æ•ˆï¼Œåº”ä»¥'sk-'å¼€å¤´")
                return False
            
            # ===========================================
            # 3. åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
            # ===========================================
            # æ³¨æ„ï¼šOpenAIå®¢æˆ·ç«¯ä¸éœ€è¦æ‰‹åŠ¨å…³é—­ï¼ŒPythonçš„åƒåœ¾å›æ”¶ä¼šè‡ªåŠ¨å¤„ç†è¿æ¥
            try:
                self.client = OpenAI(api_key=self.api_key)
                if self.log_queue:
                    self.log_queue.put("OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯å¤±è´¥: {e}")
                return False
            
            # ===========================================
            # 4. æ£€æŸ¥åŸºæœ¬ç³»ç»Ÿä¾èµ–
            # ===========================================
            try:
                # æ£€æŸ¥pathlibæ¨¡å—ï¼ˆç”¨äºæ–‡ä»¶è·¯å¾„å¤„ç†ï¼‰
                from pathlib import Path
                # æ£€æŸ¥dotenvæ¨¡å—ï¼ˆç”¨äºç¯å¢ƒå˜é‡åŠ è½½ï¼‰
                from dotenv import load_dotenv
                # æ£€æŸ¥reæ¨¡å—ï¼ˆç”¨äºæ­£åˆ™è¡¨è¾¾å¼å¤„ç†ï¼‰
                import re
            except ImportError as e:
                if self.log_queue:
                    self.log_queue.put(f"é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç³»ç»Ÿä¾èµ–: {e}")
                return False
            
            # ===========================================
            # 5. å¯ç”¨æ€§æ£€æŸ¥é€šè¿‡
            # ===========================================
            if self.log_queue:
                self.log_queue.put("LLMè®ºæ–‡æ€»ç»“å·¥å…·å¯ç”¨æ€§æ£€æŸ¥é€šè¿‡")
            return True
            
        except Exception as e:
            if self.log_queue:
                self.log_queue.put(f"é”™è¯¯: å·¥å…·å¯ç”¨æ€§æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            return False
    
    def _execute_impl(self, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œè®ºæ–‡æ€»ç»“çš„ä¸»è¦é€»è¾‘ - å®Œæ•´çš„å·¥ä½œæµç¨‹å®ç°
        
        è¿™æ˜¯æ•´ä¸ªLLMè®ºæ–‡æ€»ç»“å·¥å…·çš„æ ¸å¿ƒæ‰§è¡Œå‡½æ•°ï¼ŒæŒ‰ç…§ä¸¥æ ¼çš„é¡ºåºè°ƒç”¨å››ä¸ªå…³é”®å‡½æ•°ï¼š
        1. get_or_create_assistant() - è·å–æˆ–åˆ›å»ºOpenAI Assistantå®ä¾‹
        2. upload_pdf_to_openai() - ä¸Šä¼ PDFæ–‡ä»¶åˆ°OpenAIå¹³å°
        3. generate_summary() - ç”Ÿæˆè®ºæ–‡çš„ç»“æ„åŒ–æ€»ç»“
        4. parse_structured_response() - è§£æLLMå“åº”ä¸ºæ ‡å‡†æ ¼å¼
        
        æ‰§è¡Œæµç¨‹è¯¦è§£:
        1. å‚æ•°æå–å’Œåˆå§‹åŒ– - ä»kwargsä¸­è·å–æ‰€æœ‰å·²éªŒè¯çš„å‚æ•°
        2. è®°å½•å¼€å§‹æ—¶é—´ - ç”¨äºè®¡ç®—æ€»å¤„ç†æ—¶é—´
        3. è·å–æ–‡ä»¶ä¿¡æ¯ - è®¡ç®—PDFæ–‡ä»¶å¤§å°ç­‰å…ƒæ•°æ®
        4. Assistantç®¡ç† - ç¡®ä¿æœ‰å¯ç”¨çš„OpenAI Assistantå®ä¾‹
        5. æ–‡ä»¶ä¸Šä¼  - å°†PDFæ–‡ä»¶ä¸Šä¼ åˆ°OpenAIè¿›è¡Œå¤„ç†
        6. æ€»ç»“ç”Ÿæˆ - è°ƒç”¨OpenAI APIç”Ÿæˆè®ºæ–‡æ€»ç»“
        7. å“åº”è§£æ - å°†åŸå§‹å“åº”è§£æä¸ºç»“æ„åŒ–æ•°æ®
        8. ç»“æœç»„è£… - æŒ‰ç…§get_metadata()å®šä¹‰çš„æ ¼å¼ç»„è£…è¿”å›æ•°æ®
        9. èµ„æºæ¸…ç† - æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’ŒOpenAIèµ„æº
        10. é”™è¯¯å¤„ç† - å…¨ç¨‹å¼‚å¸¸æ•è·å’Œé”™è¯¯ä¿¡æ¯è®°å½•
        
        å‚æ•°:
            pdf_path (str): PDFæ–‡ä»¶çš„å®Œæ•´è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
            title (str, optional): è®ºæ–‡æ ‡é¢˜ï¼Œç”¨äºæä¾›ä¸Šä¸‹æ–‡
            abstract (str, optional): è®ºæ–‡æ‘˜è¦ï¼Œç”¨äºè¾…åŠ©ç†è§£
            language (str, optional): è¾“å‡ºè¯­è¨€ï¼Œé»˜è®¤'English'
            model (str, optional): OpenAIæ¨¡å‹ï¼Œé»˜è®¤'gpt-4o'
            temperature (float, optional): æ¨¡å‹æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤0.1
        
        è¿”å›:
            Dict[str, Any]: ä¸¥æ ¼æŒ‰ç…§get_metadata()ä¸­å®šä¹‰çš„schemaè¿”å›
            {
                'success': bool,  # æ“ä½œæ˜¯å¦æˆåŠŸå®Œæˆ
                'summary': {      # ç»“æ„åŒ–çš„è®ºæ–‡æ€»ç»“å†…å®¹
                    'motivation': str,     # ç ”ç©¶åŠ¨æœº
                    'methodology': str,    # æ–¹æ³•ç­–ç•¥  
                    'contributions': str,  # ä¸»è¦è´¡çŒ®
                    'challenges': str      # æŒ‘æˆ˜å±€é™
                },
                'metadata': {     # å¤„ç†è¿‡ç¨‹çš„å…ƒæ•°æ®ä¿¡æ¯
                    'model_used': str,        # å®é™…ä½¿ç”¨çš„OpenAIæ¨¡å‹
                    'processing_time': float, # å¤„ç†è€—æ—¶ï¼ˆç§’ï¼‰
                    'file_size': int,         # PDFæ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
                    'language': str           # è¾“å‡ºè¯­è¨€
                },
                'raw_response': str,  # OpenAI Assistantçš„åŸå§‹å“åº”æ–‡æœ¬
                'error': str          # é”™è¯¯ä¿¡æ¯ï¼ˆä»…åœ¨successä¸ºfalseæ—¶å­˜åœ¨ï¼‰
            }
        
        å¼‚å¸¸å¤„ç†:
            - æ•è·æ‰€æœ‰å¯èƒ½çš„å¼‚å¸¸å¹¶è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
            - ç¡®ä¿å³ä½¿å‘ç”Ÿé”™è¯¯ä¹Ÿè¿”å›æ ‡å‡†æ ¼å¼çš„ç»“æœ
            - è‡ªåŠ¨æ¸…ç†å·²åˆ›å»ºçš„ä¸´æ—¶èµ„æº
        """
        
        # ===========================================
        # 1. å‚æ•°æå–å’Œåˆå§‹åŒ–
        # ===========================================
        if self.log_queue:
            self.log_queue.put("å¼€å§‹æ‰§è¡Œè®ºæ–‡æ€»ç»“å·¥ä½œæµç¨‹")
        
        # è®°å½•å¼€å§‹æ—¶é—´ï¼Œç”¨äºè®¡ç®—æ€»å¤„ç†æ—¶é—´
        start_time = time.time()
        
        # ä»kwargsä¸­æå–æ‰€æœ‰å‚æ•°ï¼ˆè¿™äº›å‚æ•°å·²ç»é€šè¿‡validate_parameterséªŒè¯ï¼‰
        pdf_path = kwargs.get('pdf_path')
        title = kwargs.get('title')
        abstract = kwargs.get('abstract')
        language = kwargs.get('language', self.default_language)
        model = kwargs.get('model', self.default_model)
        temperature = kwargs.get('temperature', self.default_temperature)
        
        # åˆå§‹åŒ–è¿”å›ç»“æœå­—å…¸ï¼Œä¸¥æ ¼æŒ‰ç…§get_metadata()ä¸­å®šä¹‰çš„schema
        result = {
            'success': False,
            'summary': {
                'motivation': '',
                'methodology': '',
                'contributions': '',
                'challenges': ''
            },
            'metadata': {
                'model_used': model,
                'processing_time': 0.0,
                'file_size': 0,
                'language': language
            },
            'raw_response': '',
            'error': None
        }
        
        try:
            # ===========================================
            # 2. è·å–æ–‡ä»¶ä¿¡æ¯å’Œå…ƒæ•°æ®
            # ===========================================
            if self.log_queue:
                self.log_queue.put(f"æ­£åœ¨åˆ†æPDFæ–‡ä»¶: {pdf_path}")
            
            # è·å–PDFæ–‡ä»¶å¤§å°
            pdf_file = Path(pdf_path)
            file_size = pdf_file.stat().st_size
            result['metadata']['file_size'] = file_size
            
            if self.log_queue:
                self.log_queue.put(f"PDFæ–‡ä»¶å¤§å°: {file_size / (1024*1024):.2f} MB")
            
            # ===========================================
            # 3. æ­¥éª¤1: è·å–æˆ–åˆ›å»ºOpenAI Assistant
            # ===========================================
            if self.log_queue:
                self.log_queue.put("æ­¥éª¤1/4: è·å–æˆ–åˆ›å»ºOpenAI Assistant")
            
            assistant_id = self.get_or_create_assistant(model=model, temperature=temperature)
            
            if not assistant_id:
                raise Exception("æ— æ³•è·å–æˆ–åˆ›å»ºOpenAI Assistant")
            
            if self.log_queue:
                self.log_queue.put(f"âœ… Assistantåˆ›å»ºæˆåŠŸ: {assistant_id}")
            
            # ===========================================
            # 4. æ­¥éª¤2: ä¸Šä¼ PDFæ–‡ä»¶åˆ°OpenAI
            # ===========================================
            if self.log_queue:
                self.log_queue.put("æ­¥éª¤2/4: ä¸Šä¼ PDFæ–‡ä»¶åˆ°OpenAIå¹³å°")
            
            file_id = self.upload_pdf_to_openai(pdf_path)
            
            if not file_id:
                raise Exception("PDFæ–‡ä»¶ä¸Šä¼ å¤±è´¥")
            
            if self.log_queue:
                self.log_queue.put(f"âœ… PDFæ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_id}")
            
            # ===========================================
            # 5. æ­¥éª¤3: ç”Ÿæˆè®ºæ–‡æ€»ç»“
            # ===========================================
            if self.log_queue:
                self.log_queue.put("æ­¥éª¤3/4: ç”Ÿæˆè®ºæ–‡æ€»ç»“ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰")
            
            summary_result = self.generate_summary(
                file_id=file_id,
                title=title,
                abstract=abstract,
                language=language
            )
            
            if not summary_result or not summary_result.get('response'):
                raise Exception("è®ºæ–‡æ€»ç»“ç”Ÿæˆå¤±è´¥")
            
            # æå–å“åº”å†…å®¹å’Œthread_id
            raw_response = summary_result['response']
            thread_id = summary_result['thread_id']
            
            # ä¿å­˜åŸå§‹å“åº”
            result['raw_response'] = raw_response
            
            if self.log_queue:
                self.log_queue.put(f"âœ… è®ºæ–‡æ€»ç»“ç”ŸæˆæˆåŠŸï¼Œå“åº”é•¿åº¦: {len(raw_response)} å­—ç¬¦")
            
            # ===========================================
            # 6. æ­¥éª¤4: è§£æç»“æ„åŒ–å“åº”
            # ===========================================
            if self.log_queue:
                self.log_queue.put("æ­¥éª¤4/4: è§£æç»“æ„åŒ–å“åº”")
            
            parsed_summary = self.parse_structured_response(raw_response)
            
            if not parsed_summary:
                raise Exception("å“åº”è§£æå¤±è´¥")
            
            # æ›´æ–°ç»“æœä¸­çš„summaryéƒ¨åˆ†
            result['summary'] = parsed_summary
            
            if self.log_queue:
                self.log_queue.put("âœ… å“åº”è§£ææˆåŠŸ")
            
            # ===========================================
            # 7. è®¡ç®—å¤„ç†æ—¶é—´å¹¶æ ‡è®°æˆåŠŸ
            # ===========================================
            end_time = time.time()
            processing_time = end_time - start_time
            result['metadata']['processing_time'] = processing_time
            result['success'] = True
            
            if self.log_queue:
                self.log_queue.put(f"ğŸ‰ è®ºæ–‡æ€»ç»“å·¥ä½œæµç¨‹å®Œæˆï¼æ€»è€—æ—¶: {processing_time:.2f}ç§’")
            
        except Exception as e:
            # ===========================================
            # 8. å¼‚å¸¸å¤„ç†
            # ===========================================
            error_message = f"è®ºæ–‡æ€»ç»“æ‰§è¡Œå¤±è´¥: {str(e)}"
            result['error'] = error_message
            result['success'] = False
            
            # è®¡ç®—å·²ç”¨æ—¶é—´
            end_time = time.time()
            result['metadata']['processing_time'] = end_time - start_time
            
            if self.log_queue:
                self.log_queue.put(f"âŒ {error_message}")
            
            # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
            import traceback
            if self.log_queue:
                self.log_queue.put(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        
        # ===========================================
        # 9. èµ„æºæ¸…ç†
        # ===========================================
        finally:
            # æ— è®ºæ‰§è¡ŒæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½éœ€è¦æ¸…ç†OpenAIèµ„æº
            # æ¸…ç†åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­åˆ›å»ºçš„file_idå’Œthread_id
            try:
                # è·å–éœ€è¦æ¸…ç†çš„èµ„æºID
                 cleanup_file_id = locals().get('file_id')
                 cleanup_thread_id = locals().get('thread_id')
                 
                 if self.log_queue:
                     self.log_queue.put("ğŸ§¹ å¼€å§‹æ¸…ç†OpenAIèµ„æº...")
                 
                 # è°ƒç”¨cleanupå‡½æ•°æ¸…ç†èµ„æº
                 if cleanup_file_id or cleanup_thread_id:
                     cleanup_result = self.cleanup(file_id=cleanup_file_id, thread_id=cleanup_thread_id)
                     
                     if self.log_queue:
                         if cleanup_result.get('success', False):
                             self.log_queue.put("âœ… èµ„æºæ¸…ç†å®Œæˆ")
                         else:
                             self.log_queue.put(f"âš ï¸ èµ„æºæ¸…ç†éƒ¨åˆ†å¤±è´¥: {cleanup_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                
            except Exception as cleanup_error:
                # æ¸…ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯ä¸åº”è¯¥å½±å“ä¸»è¦ç»“æœ
                if self.log_queue:
                    self.log_queue.put(f"âš ï¸ èµ„æºæ¸…ç†æ—¶å‘ç”Ÿé”™è¯¯: {str(cleanup_error)}")
        
        # ===========================================
        # 10. è¿”å›æœ€ç»ˆç»“æœ
        # ===========================================
        return result
    
    def get_or_create_assistant(self, model: str = None, temperature: float = None) -> str:
        """
        è·å–ç°æœ‰çš„Assistantæˆ–åˆ›å»ºæ–°çš„Assistant
        
        åŠŸèƒ½è¯´æ˜:
        1. é¦–å…ˆæŸ¥æ‰¾æ˜¯å¦å­˜åœ¨åŒåçš„Assistant
        2. å¦‚æœå­˜åœ¨åˆ™ç›´æ¥è¿”å›å…¶ID
        3. å¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°çš„Assistant
        4. é…ç½®Assistantçš„æŒ‡ä»¤å’Œå·¥å…·
        
        å‚æ•°:
            model (str, optional): æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤ä½¿ç”¨self.default_model
            temperature (float, optional): æŒ‡å®šæ¸©åº¦å‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨self.default_temperature
        
        è¿”å›:
            str: Assistantçš„ID
        
        Assistanté…ç½®:
        - åç§°: "Academic Paper Summarizer"
        - æŒ‡ä»¤: ä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†ææŒ‡ä»¤
        - å·¥å…·: file_searchï¼ˆæ–‡ä»¶æœç´¢å’Œåˆ†æï¼‰
        - æ¨¡å‹: æŒ‡å®šçš„æ¨¡å‹æˆ–é»˜è®¤æ¨¡å‹
        
        å¼‚å¸¸å¤„ç†:
        - OpenAI APIè°ƒç”¨å¤±è´¥
        - ç½‘ç»œè¿æ¥é—®é¢˜
        - æƒé™ä¸è¶³
        """
        try:
            # ===========================================
            # 1. ä½¿ç”¨ç¼“å­˜çš„Assistant IDï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            # ===========================================
            if self.assistant_id:
                if self.log_queue:
                    self.log_queue.put(f"ä½¿ç”¨ç¼“å­˜çš„Assistant ID: {self.assistant_id}")
                return self.assistant_id
            
            # ===========================================
            # 2. è®¾ç½®é»˜è®¤å‚æ•°
            # ===========================================
            if model is None:
                model = self.default_model
            if temperature is None:
                temperature = self.default_temperature
            
            # ===========================================
            # 3. æŸ¥æ‰¾ç°æœ‰çš„Assistant
            # ===========================================
            if self.log_queue:
                self.log_queue.put("æ­£åœ¨æŸ¥æ‰¾ç°æœ‰çš„Assistant...")
            
            try:
                # è·å–æ‰€æœ‰Assistantåˆ—è¡¨
                assistants = self.client.beta.assistants.list(limit=100)
                
                # æŸ¥æ‰¾åŒåAssistant
                for assistant in assistants.data:
                    if assistant.name == self.assistant_name:
                        self.assistant_id = assistant.id
                        if self.log_queue:
                            self.log_queue.put(f"æ‰¾åˆ°ç°æœ‰Assistant: {assistant.id}")
                        return self.assistant_id
                        
            except Exception as e:
                if self.log_queue:
                    self.log_queue.put(f"æŸ¥æ‰¾Assistantæ—¶å‡ºé”™: {e}ï¼Œå°†åˆ›å»ºæ–°çš„Assistant")
            
            # ===========================================
            # 4. åˆ›å»ºæ–°çš„Assistant
            # ===========================================
            if self.log_queue:
                self.log_queue.put(f"åˆ›å»ºæ–°çš„Assistantï¼Œæ¨¡å‹: {model}ï¼Œæ¸©åº¦: {temperature}")
            
            # æ„å»ºä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åˆ†ææŒ‡ä»¤
            instructions = self._build_assistant_instructions()
            
            # åˆ›å»ºAssistant
            assistant = self.client.beta.assistants.create(
                name=self.assistant_name,
                instructions=instructions,
                model=model,
                temperature=temperature,
                tools=[
                    {"type": "file_search"}  # å¯ç”¨æ–‡ä»¶æœç´¢åŠŸèƒ½
                ]
            )
            
            # ===========================================
            # 5. ç¼“å­˜Assistant ID
            # ===========================================
            self.assistant_id = assistant.id
            
            if self.log_queue:
                self.log_queue.put(f"æˆåŠŸåˆ›å»ºAssistant: {assistant.id}")
            
            return self.assistant_id
            
        except Exception as e:
            error_msg = f"è·å–æˆ–åˆ›å»ºAssistantå¤±è´¥: {e}"
            if self.log_queue:
                self.log_queue.put(f"é”™è¯¯: {error_msg}")
            raise Exception(error_msg)
    
    def _build_assistant_instructions(self) -> str:
        """
        æ„å»ºAssistantçš„è¯¦ç»†æŒ‡ä»¤
        
        è¿”å›:
            str: å®Œæ•´çš„AssistantæŒ‡ä»¤æ–‡æœ¬
        
        æŒ‡ä»¤å†…å®¹:
        1. è§’è‰²å®šä¹‰å’Œä¸“ä¸šèƒŒæ™¯
        2. ä»»åŠ¡ç›®æ ‡å’Œè¾“å‡ºè¦æ±‚
        3. åˆ†ææ¡†æ¶å’Œç»“æ„åŒ–è¾“å‡ºæ ¼å¼
        4. è´¨é‡æ ‡å‡†å’Œæ³¨æ„äº‹é¡¹
        5. è¯­è¨€é€‚åº”æ€§è¯´æ˜
        """
        instructions = """
            You are a professional academic paper analysis expert with deep research background and extensive paper review experience. Your task is to conduct in-depth analysis of the uploaded PDF academic paper and generate a structured summary report.

            ## Core Task
            Analyze the academic paper and provide a structured summary in the following four dimensions:

            1. **Motivation of the study**
            - Identify the core problem the paper aims to solve
            - Analyze research background and limitations of existing methods
            - Explain the importance and necessity of the research
            - Describe the theoretical or practical value of the study

            2. **Methodology or strategy**
            - Describe in detail the research methods adopted in the paper
            - Explain the technical approach and implementation plan
            - Analyze the innovation points and advantages of the method
            - Explain experimental design and evaluation strategies

            3. **Key contributions**
            - Summarize the core innovation points of the paper
            - Quantitatively analyze experimental results and performance improvements
            - Evaluate theoretical contributions and practical value
            - Compare advantages over existing methods

            4. **Limitations or challenges**
            - Identify limitations of the proposed method
            - Analyze unresolved problems and challenges
            - Discuss scope of applicability and boundary conditions
            - Propose future research directions

            ## Critical Output Format Requirements
            You MUST structure your response exactly as follows to ensure proper parsing:

            **Motivation of the study:**
            [Your analysis of the research motivation here - 200-300 words]

            **Methodology or strategy:**
            [Your analysis of the methodology here - 200-300 words]

            **Key contributions:**
            [Your analysis of the key contributions here - 200-300 words]

            **Limitations or challenges:**
            [Your analysis of the limitations and challenges here - 200-300 words]

            ## Language Adaptation Requirements
            **IMPORTANT**: You must adapt your response language and section headers based on the user's prompt:
            
            - If the user's prompt is in Chinese or requests Chinese output, respond in Chinese and use Chinese section headers:
              * **ç ”ç©¶åŠ¨æœº:** instead of **Motivation of the study:**
              * **æ–¹æ³•æˆ–ç­–ç•¥:** instead of **Methodology or strategy:**
              * **ä¸»è¦è´¡çŒ®:** instead of **Key contributions:**
              * **æŒ‘æˆ˜æˆ–å±€é™:** instead of **Limitations or challenges:**
            
            - If the user's prompt is in English or requests English output, respond in English with English section headers as shown above.
            
            - Always match the language of your analysis content to the language requested in the user's prompt.
            - Maintain the same professional quality and structure regardless of the output language.

            ## Quality Requirements
            1. **Structured Output**: Strictly organize content according to the four dimensions with exact headers
            2. **Professional Accuracy**: Use precise academic terminology and concepts
            3. **Concise and Clear**: Control each dimension to 200-300 words
            4. **Objective and Neutral**: Conduct objective analysis based on paper content
            5. **Logical Clarity**: Ensure coherent analysis logic with highlighted key points
            6. **Language Consistency**: Maintain consistent language throughout the response

            ## Analysis Strategy
            - Carefully read the paper's abstract, introduction, methods, experiments, and conclusion sections
            - Pay attention to figures, tables, formulas, and experimental data
            - Understand the paper's positioning and contributions in the relevant field
            - Identify limitations and future work explicitly mentioned by the authors

            Please generate a high-quality structured paper summary based on the uploaded PDF file content, following the exact format requirements above and adapting the language according to the user's request.
        """
        return instructions.strip()
    
    def upload_pdf_to_openai(self, pdf_path: str) -> str:
        """
        ä¸Šä¼ PDFæ–‡ä»¶åˆ°OpenAI
        
        åŠŸèƒ½è¯´æ˜:
        1. ä»¥äºŒè¿›åˆ¶æ¨¡å¼è¯»å–PDFæ–‡ä»¶
        2. è°ƒç”¨OpenAI Files APIä¸Šä¼ æ–‡ä»¶
        3. è¿”å›æ–‡ä»¶IDä¾›åç»­ä½¿ç”¨
        
        æ³¨æ„:
        - æ–‡ä»¶éªŒè¯å·²åœ¨validate_parameters()ä¸­å®Œæˆ
        - OpenAIå®¢æˆ·ç«¯å·²åœ¨is_available()ä¸­åˆå§‹åŒ–
        - æ­¤å‡½æ•°ä¸“æ³¨äºæ ¸å¿ƒä¸Šä¼ é€»è¾‘
        
        å‚æ•°:
            pdf_path (str): PDFæ–‡ä»¶çš„å®Œæ•´è·¯å¾„ï¼ˆå·²éªŒè¯ï¼‰
        
        è¿”å›:
            str: ä¸Šä¼ åçš„æ–‡ä»¶ID
        
        å¼‚å¸¸:
            Exception: å½“æ–‡ä»¶ä¸Šä¼ å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸ï¼ŒåŒ…å«è¯¦ç»†é”™è¯¯ä¿¡æ¯
        """
        try:
            # ===========================================
            # 1. è·å–æ–‡ä»¶ä¿¡æ¯ç”¨äºæ—¥å¿—è®°å½•
            # ===========================================
            pdf_file = Path(pdf_path)
            file_size = pdf_file.stat().st_size
            
            # è®°å½•å¼€å§‹ä¸Šä¼ 
            if self.log_queue:
                self.log_queue.put(f"ğŸ“„ å‡†å¤‡ä¸Šä¼ PDFæ–‡ä»¶: {pdf_file.name} ({file_size/1024/1024:.2f}MB)")
                self.log_queue.put("ğŸ”„ æ­£åœ¨ä¸Šä¼ PDFæ–‡ä»¶åˆ°OpenAI...")
            
            # ===========================================
            # 2. ä¸Šä¼ æ–‡ä»¶åˆ°OpenAI
            # ===========================================
            with open(pdf_path, 'rb') as file:
                # è°ƒç”¨OpenAI Files APIä¸Šä¼ æ–‡ä»¶
                # purpose="assistants" è¡¨ç¤ºæ–‡ä»¶ç”¨äºAssistant API
                file_response = self.client.files.create(
                    file=file,
                    purpose="assistants"
                )
            
            # ===========================================
            # 3. è·å–å¹¶éªŒè¯æ–‡ä»¶ID
            # ===========================================
            file_id = file_response.id
            if not file_id:
                error_msg = "æ–‡ä»¶ä¸Šä¼ æˆåŠŸä½†æœªè¿”å›æœ‰æ•ˆçš„æ–‡ä»¶ID"
                if self.log_queue:
                    self.log_queue.put(f"âŒ {error_msg}")
                raise Exception(error_msg)
            
            # ===========================================
            # 4. è®°å½•æˆåŠŸä¿¡æ¯
            # ===========================================
            if self.log_queue:
                self.log_queue.put(f"âœ… PDFæ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼æ–‡ä»¶ID: {file_id}")
                self.log_queue.put(f"ğŸ“Š æ–‡ä»¶ä¿¡æ¯: {pdf_file.name} ({file_size/1024/1024:.2f}MB)")
            
            return file_id
            
        except openai.APIError as e:
            # ===========================================
            # OpenAI APIç›¸å…³é”™è¯¯å¤„ç†
            # ===========================================
            error_msg = f"OpenAI APIé”™è¯¯: {str(e)}"
            if hasattr(e, 'status_code'):
                if e.status_code == 400:
                    error_msg += " - è¯·æ±‚å‚æ•°é”™è¯¯æˆ–æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ"
                elif e.status_code == 401:
                    error_msg += " - APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ"
                elif e.status_code == 403:
                    error_msg += " - æƒé™ä¸è¶³æˆ–APIé…é¢å·²ç”¨å®Œ"
                elif e.status_code == 413:
                    error_msg += " - æ–‡ä»¶å¤§å°è¶…å‡ºOpenAIé™åˆ¶"
                elif e.status_code == 429:
                    error_msg += " - è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•"
                elif e.status_code >= 500:
                    error_msg += " - OpenAIæœåŠ¡å™¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•"
            
            if self.log_queue:
                self.log_queue.put(f"âŒ {error_msg}")
            raise Exception(error_msg)
            
        except Exception as e:
            # ===========================================
            # å…¶ä»–å¼‚å¸¸å¤„ç†
            # ===========================================
            error_msg = f"ä¸Šä¼ PDFæ–‡ä»¶å¤±è´¥: {str(e)}"
            if self.log_queue:
                self.log_queue.put(f"âŒ {error_msg}")
            raise Exception(error_msg)
    
    def generate_summary(self, file_id: str, title: str = None, abstract: str = None, 
                        language: str = 'English') -> str:
        """
        ä½¿ç”¨OpenAI Assistantç”Ÿæˆè®ºæ–‡æ€»ç»“
        
        åŠŸèƒ½è¯´æ˜:
        1. æ„å»ºæ€»ç»“è¯·æ±‚çš„æŒ‡ä»¤
        2. åˆ›å»ºå¯¹è¯çº¿ç¨‹
        3. å‘é€åŒ…å«PDFæ–‡ä»¶çš„æ¶ˆæ¯
        4. å¯åŠ¨Assistantè¿è¡Œ
        5. ç­‰å¾…å¹¶è·å–ç»“æœ
        
        æ³¨æ„:
        - æ–‡ä»¶éªŒè¯å’ŒAssistantåˆå§‹åŒ–å·²åœ¨å…¶ä»–å‡½æ•°ä¸­å®Œæˆ
        - æ­¤å‡½æ•°ä¸“æ³¨äºæ ¸å¿ƒçš„æ€»ç»“ç”Ÿæˆé€»è¾‘
        - å‡è®¾file_idæ˜¯æœ‰æ•ˆçš„å·²ä¸Šä¼ æ–‡ä»¶ID
        
        å‚æ•°:
            file_id (str): å·²ä¸Šä¼ çš„PDFæ–‡ä»¶IDï¼ˆå·²éªŒè¯ï¼‰
            title (str, optional): è®ºæ–‡æ ‡é¢˜
            abstract (str, optional): è®ºæ–‡æ‘˜è¦
            language (str): è¾“å‡ºè¯­è¨€
        
        è¿”å›:
            str: Assistantç”Ÿæˆçš„åŸå§‹å“åº”æ–‡æœ¬
        
        å¤„ç†æµç¨‹:
        1. æ ¹æ®è¯­è¨€é€‰æ‹©ç›¸åº”çš„ç« èŠ‚æ ‡é¢˜
        2. æ„å»ºè¯¦ç»†çš„åˆ†ææŒ‡ä»¤
        3. åˆ›å»ºåŒ…å«æ–‡ä»¶é™„ä»¶çš„æ¶ˆæ¯
        4. ç›‘æ§è¿è¡ŒçŠ¶æ€ç›´åˆ°å®Œæˆ
        5. æå–å¹¶è¿”å›å“åº”å†…å®¹
        """
        try:
            # ===========================================
            # 1. æ ¹æ®è¯­è¨€é€‰æ‹©å¯¹åº”çš„ç« èŠ‚æ ‡é¢˜æ¨¡æ¿
            # ===========================================
            # è·å–å½“å‰è¯­è¨€çš„ç« èŠ‚æ ‡é¢˜é…ç½®
            section_headers = SECTION_HEADERS.get(language, SECTION_HEADERS['English'])
            
            if self.log_queue:
                self.log_queue.put(f"ğŸ“ å¼€å§‹ç”Ÿæˆ{language}æ€»ç»“ï¼Œä½¿ç”¨æ–‡ä»¶ID: {file_id}")
            
            # ===========================================
            # 2. æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¾“å…¥æ–‡æœ¬
            # ===========================================
            context_info = []
            
            # æ·»åŠ è®ºæ–‡æ ‡é¢˜ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
            if title and title.strip():
                context_info.append(f"è®ºæ–‡æ ‡é¢˜: {title.strip()}")
                if self.log_queue:
                    self.log_queue.put(f"ğŸ“‹ å·²æ·»åŠ è®ºæ–‡æ ‡é¢˜: {title.strip()[:50]}...")
            
            # æ·»åŠ è®ºæ–‡æ‘˜è¦ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
            if abstract and abstract.strip():
                context_info.append(f"è®ºæ–‡æ‘˜è¦: {abstract.strip()}")
                if self.log_queue:
                    self.log_queue.put(f"ğŸ“„ å·²æ·»åŠ è®ºæ–‡æ‘˜è¦ä¿¡æ¯")
            
            # æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
            context_text = "\n\n".join(context_info) if context_info else ""
            
            # ===========================================
            # 3. æ„å»ºè¯¦ç»†çš„åˆ†ææŒ‡ä»¤
            # ===========================================
            # åˆ›å»ºç»“æ„åŒ–çš„åˆ†ææç¤ºè¯
            # æ ¹æ®è¯­è¨€é€‰æ‹©æ„å»ºç®€æ´çš„åˆ†ææç¤º
            if language == 'Chinese':
                analysis_prompt = f"""
                    {context_text}

                    è¯·ä½ é˜…è¯»PDFæ–‡ä»¶çš„å†…å®¹å¹¶å°†æ€»ç»“å†…å®¹ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºä¸­æ–‡æ€»ç»“ï¼š

                    **{section_headers['motivation']}:**
                    [æ‚¨çš„åˆ†æå†…å®¹]

                    **{section_headers['methodology']}:**
                    [æ‚¨çš„åˆ†æå†…å®¹]

                    **{section_headers['contributions']}:**
                    [æ‚¨çš„åˆ†æå†…å®¹]

                    **{section_headers['challenges']}:**
                    [æ‚¨çš„åˆ†æå†…å®¹]
                """.strip()
            else:
                analysis_prompt = f"""
                    {context_text}

                    Please read the PDF file content carefully and provide your analysis summary strictly following this exact format:

                    **{section_headers['motivation']}:**
                    [Your analysis content]

                    **{section_headers['methodology']}:**
                    [Your analysis content]

                    **{section_headers['contributions']}:**
                    [Your analysis content]

                    **{section_headers['challenges']}:**
                    [Your analysis content]
                """.strip()
            
            if self.log_queue:
                self.log_queue.put("ğŸ”§ å·²æ„å»ºåˆ†ææŒ‡ä»¤æ¨¡æ¿")
            
            # ===========================================
            # 4. åˆ›å»ºå¯¹è¯çº¿ç¨‹
            # ===========================================
            if self.log_queue:
                self.log_queue.put("ğŸ§µ æ­£åœ¨åˆ›å»ºå¯¹è¯çº¿ç¨‹...")
            
            # ä½¿ç”¨OpenAI APIåˆ›å»ºæ–°çš„å¯¹è¯çº¿ç¨‹
            thread = self.client.beta.threads.create()
            thread_id = thread.id
            
            if self.log_queue:
                self.log_queue.put(f"âœ… å¯¹è¯çº¿ç¨‹åˆ›å»ºæˆåŠŸï¼ŒID: {thread_id}")
            
            # ===========================================
            # 5. å‘é€åŒ…å«PDFæ–‡ä»¶é™„ä»¶çš„æ¶ˆæ¯
            # ===========================================
            if self.log_queue:
                self.log_queue.put("ğŸ“¤ æ­£åœ¨å‘é€åˆ†æè¯·æ±‚æ¶ˆæ¯...")
            
            # åˆ›å»ºåŒ…å«æ–‡ä»¶é™„ä»¶çš„æ¶ˆæ¯
            # attachmentså‚æ•°ç”¨äºå°†ä¸Šä¼ çš„PDFæ–‡ä»¶å…³è”åˆ°æ¶ˆæ¯
            message = self.client.beta.threads.messages.create(
                thread_id=thread_id,
                role="user",
                content=analysis_prompt,
                attachments=[
                    {
                        "file_id": file_id,
                        "tools": [{"type": "file_search"}]  # å¯ç”¨æ–‡ä»¶æœç´¢å·¥å…·
                    }
                ]
            )
            
            if self.log_queue:
                self.log_queue.put(f"âœ… æ¶ˆæ¯å‘é€æˆåŠŸï¼Œæ¶ˆæ¯ID: {message.id}")
            
            # ===========================================
            # 6. å¯åŠ¨Assistantè¿è¡Œå¹¶ç›‘æ§çŠ¶æ€
            # ===========================================
            if self.log_queue:
                self.log_queue.put("ğŸš€ å¯åŠ¨Assistantåˆ†æä»»åŠ¡...")
            
            # åˆ›å»ºè¿è¡Œå®ä¾‹ï¼Œè®©Assistantå¼€å§‹å¤„ç†
            run = self.client.beta.threads.runs.create(
                thread_id=thread_id,
                assistant_id=self.assistant_id
            )
            
            run_id = run.id
            if self.log_queue:
                self.log_queue.put(f"â³ Assistantè¿è¡Œå·²å¯åŠ¨ï¼Œè¿è¡ŒID: {run_id}")
            
            # ===========================================
            # 7. è½®è¯¢è¿è¡ŒçŠ¶æ€ç›´åˆ°å®Œæˆ
            # ===========================================
            max_wait_time = 300  # æœ€å¤§ç­‰å¾…æ—¶é—´ï¼š5åˆ†é’Ÿ
            check_interval = 2   # æ£€æŸ¥é—´éš”ï¼š2ç§’
            elapsed_time = 0
            
            while elapsed_time < max_wait_time:
                # è·å–å½“å‰è¿è¡ŒçŠ¶æ€
                run_status = self.client.beta.threads.runs.retrieve(
                    thread_id=thread_id,
                    run_id=run_id
                )
                
                current_status = run_status.status
                
                # æ£€æŸ¥è¿è¡Œæ˜¯å¦å®Œæˆ
                if current_status == "completed":
                    if self.log_queue:
                        self.log_queue.put("âœ… Assistantåˆ†æå®Œæˆï¼")
                    break
                elif current_status == "failed":
                    error_msg = f"Assistantè¿è¡Œå¤±è´¥: {run_status.last_error}"
                    if self.log_queue:
                        self.log_queue.put(f"âŒ {error_msg}")
                    raise Exception(error_msg)
                elif current_status == "cancelled":
                    error_msg = "Assistantè¿è¡Œè¢«å–æ¶ˆ"
                    if self.log_queue:
                        self.log_queue.put(f"âŒ {error_msg}")
                    raise Exception(error_msg)
                elif current_status == "expired":
                    error_msg = "Assistantè¿è¡Œè¶…æ—¶è¿‡æœŸ"
                    if self.log_queue:
                        self.log_queue.put(f"âŒ {error_msg}")
                    raise Exception(error_msg)
                else:
                    # è¿è¡Œä¸­çŠ¶æ€ï¼šqueued, in_progress, requires_action
                    if self.log_queue and elapsed_time % 10 == 0:  # æ¯10ç§’æŠ¥å‘Šä¸€æ¬¡çŠ¶æ€
                        self.log_queue.put(f"â³ Assistantæ­£åœ¨åˆ†æä¸­... çŠ¶æ€: {current_status} ({elapsed_time}s)")
                
                # ç­‰å¾…åç»§ç»­æ£€æŸ¥
                time.sleep(check_interval)
                elapsed_time += check_interval
            
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if elapsed_time >= max_wait_time:
                error_msg = f"Assistantè¿è¡Œè¶…æ—¶ï¼ˆ{max_wait_time}ç§’ï¼‰ï¼Œè¯·ç¨åé‡è¯•"
                if self.log_queue:
                    self.log_queue.put(f"âŒ {error_msg}")
                raise Exception(error_msg)
            
            # ===========================================
            # 8. è·å–å¹¶æå–æœ€ç»ˆå“åº”å†…å®¹
            # ===========================================
            if self.log_queue:
                self.log_queue.put("ğŸ“¥ æ­£åœ¨è·å–åˆ†æç»“æœ...")
            
            # è·å–çº¿ç¨‹ä¸­çš„æ‰€æœ‰æ¶ˆæ¯
            messages = self.client.beta.threads.messages.list(
                thread_id=thread_id,
                order="desc",  # æŒ‰æ—¶é—´å€’åºï¼Œæœ€æ–°çš„åœ¨å‰
                limit=10       # é™åˆ¶è·å–æ•°é‡
            )
            
            # æŸ¥æ‰¾Assistantçš„å“åº”æ¶ˆæ¯
            assistant_response = None
            for message in messages.data:
                if message.role == "assistant":
                    # æå–æ¶ˆæ¯å†…å®¹
                    if message.content and len(message.content) > 0:
                        # è·å–ç¬¬ä¸€ä¸ªå†…å®¹å—çš„æ–‡æœ¬
                        content_block = message.content[0]
                        if hasattr(content_block, 'text') and hasattr(content_block.text, 'value'):
                            assistant_response = content_block.text.value
                            break
            
            # éªŒè¯æ˜¯å¦è·å–åˆ°æœ‰æ•ˆå“åº”
            if not assistant_response:
                error_msg = "æœªèƒ½è·å–åˆ°Assistantçš„æœ‰æ•ˆå“åº”"
                if self.log_queue:
                    self.log_queue.put(f"âŒ {error_msg}")
                raise Exception(error_msg)
            
            # ===========================================
            # 9. è®°å½•æˆåŠŸä¿¡æ¯å¹¶è¿”å›ç»“æœ
            # ===========================================
            response_length = len(assistant_response)
            if self.log_queue:
                self.log_queue.put(f"âœ… è®ºæ–‡æ€»ç»“ç”ŸæˆæˆåŠŸï¼å“åº”é•¿åº¦: {response_length} å­—ç¬¦")
                self.log_queue.put(f"ğŸ“Š å¤„ç†è€—æ—¶: {elapsed_time} ç§’")
            
            # è¿”å›å“åº”å†…å®¹å’Œthread_idï¼ˆç”¨äºåç»­æ¸…ç†ï¼‰
            return {
                'response': assistant_response,
                'thread_id': thread_id
            }
            
        except openai.APIError as e:
            # ===========================================
            # OpenAI APIç›¸å…³é”™è¯¯å¤„ç†
            # ===========================================
            error_msg = f"OpenAI APIé”™è¯¯: {str(e)}"
            if hasattr(e, 'status_code'):
                if e.status_code == 400:
                    error_msg += " - è¯·æ±‚å‚æ•°é”™è¯¯æˆ–æ–‡ä»¶æ— æ³•å¤„ç†"
                elif e.status_code == 401:
                    error_msg += " - APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ"
                elif e.status_code == 403:
                    error_msg += " - æƒé™ä¸è¶³æˆ–APIé…é¢å·²ç”¨å®Œ"
                elif e.status_code == 404:
                    error_msg += " - Assistantæˆ–æ–‡ä»¶æœªæ‰¾åˆ°"
                elif e.status_code == 429:
                    error_msg += " - è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•"
                elif e.status_code >= 500:
                    error_msg += " - OpenAIæœåŠ¡å™¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•"
            
            if self.log_queue:
                self.log_queue.put(f"âŒ {error_msg}")
            raise Exception(error_msg)
            
        except Exception as e:
            # ===========================================
            # å…¶ä»–å¼‚å¸¸å¤„ç†
            # ===========================================
            error_msg = f"ç”Ÿæˆè®ºæ–‡æ€»ç»“å¤±è´¥: {str(e)}"
            if self.log_queue:
                self.log_queue.put(f"âŒ {error_msg}")
            raise Exception(error_msg)
    
    def parse_structured_response(self, raw_response: str) -> Dict[str, str]:
        """
        è§£æAssistantè¿”å›çš„ç»“æ„åŒ–å“åº”
        
        åŠŸèƒ½è¯´æ˜:
        1. æ¸…ç†å“åº”æ–‡æœ¬ä¸­çš„ç‰¹æ®Šæ ‡è®°
        2. æå–å››ä¸ªä¸»è¦éƒ¨åˆ†çš„å†…å®¹
        3. éªŒè¯æå–ç»“æœçš„å®Œæ•´æ€§
        4. è¿”å›ç»“æ„åŒ–çš„å­—å…¸æ•°æ®
        
        å‚æ•°:
            raw_response (str): Assistantçš„åŸå§‹å“åº”æ–‡æœ¬
        
        è¿”å›:
            Dict[str, str]: ç»“æ„åŒ–çš„æ€»ç»“å†…å®¹
            {
                'motivation': str,    # ç ”ç©¶åŠ¨æœº
                'methodology': str,   # æ–¹æ³•ç­–ç•¥
                'contributions': str, # ä¸»è¦è´¡çŒ®
                'challenges': str     # æŒ‘æˆ˜å±€é™
            }
        
        è§£æè§„åˆ™:
        - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…â‘ â‘¡â‘¢â‘£æ ‡è®°çš„å†…å®¹
        - æ¸…ç†OpenAIç‰¹æœ‰çš„å¼•ç”¨æ ‡è®°ã€ã€‘
        - å¤„ç†å¯èƒ½çš„æ ¼å¼å˜åŒ–å’Œå¼‚å¸¸æƒ…å†µ
        - ç¡®ä¿æ¯ä¸ªéƒ¨åˆ†éƒ½æœ‰æœ‰æ•ˆå†…å®¹
        """
        
        # åˆå§‹åŒ–ç»“æœå­—å…¸ï¼Œä½¿ç”¨é»˜è®¤å€¼é˜²æ­¢ç¼ºå¤±
        result = {
            'motivation': '',
            'methodology': '',
            'contributions': '',
            'challenges': ''
        }
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šæ¸…ç†å“åº”æ–‡æœ¬
            # ç§»é™¤OpenAIç‰¹æœ‰çš„å¼•ç”¨æ ‡è®°ã€æ•°å­—ã€‘ï¼Œä¾‹å¦‚ã€1ã€‘ã€2ã€‘ç­‰
            cleaned_response = re.sub(r'ã€\d+ã€‘', '', raw_response)
            
            # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦å’Œæ¢è¡Œç¬¦ï¼Œç»Ÿä¸€æ ¼å¼
            cleaned_response = re.sub(r'\n+', '\n', cleaned_response.strip())
            
            # ç¬¬äºŒæ­¥ï¼šå®šä¹‰ç²¾ç¡®åŒ¹é…æ¨¡å¼
            # ä¸¥æ ¼æŒ‰ç…§SECTION_HEADERSä¸­å®šä¹‰çš„æ ‡é¢˜è¿›è¡ŒåŒ¹é…
            patterns = {
                'motivation': [
                    # è‹±æ–‡æ ‡é¢˜ï¼šMotivation of the study
                    r'(?:â‘ |1\.)\s*(?:\*\*)?Motivation of the study(?:\*\*)?\s*[:ï¼š]?\s*(.*?)(?=(?:â‘¡|2\.|\*\*(?:Methodology or strategy)|$))',
                    r'\*\*Motivation of the study\*\*\s*[:ï¼š]?\s*(.*?)(?=\*\*(?:Methodology or strategy|Key contributions)|$)',
                    r'Motivation of the study\s*[:ï¼š]\s*(.*?)(?=(?:Methodology or strategy|Key contributions|Limitations or challenges)|$)',
                    # ä¸­æ–‡æ ‡é¢˜ï¼šç ”ç©¶åŠ¨æœº
                    r'(?:â‘ |1\.)\s*(?:\*\*)?ç ”ç©¶åŠ¨æœº(?:\*\*)?\s*[:ï¼š]?\s*(.*?)(?=(?:â‘¡|2\.|\*\*(?:æ–¹æ³•æˆ–ç­–ç•¥)|$))',
                    r'\*\*ç ”ç©¶åŠ¨æœº\*\*\s*[:ï¼š]?\s*(.*?)(?=\*\*(?:æ–¹æ³•æˆ–ç­–ç•¥|ä¸»è¦è´¡çŒ®)|$)',
                    r'ç ”ç©¶åŠ¨æœº\s*[:ï¼š]\s*(.*?)(?=(?:æ–¹æ³•æˆ–ç­–ç•¥|ä¸»è¦è´¡çŒ®|æŒ‘æˆ˜æˆ–å±€é™)|$)'
                ],
                'methodology': [
                    # è‹±æ–‡æ ‡é¢˜ï¼šMethodology or strategy
                    r'(?:â‘¡|2\.)\s*(?:\*\*)?Methodology or strategy(?:\*\*)?\s*[:ï¼š]?\s*(.*?)(?=(?:â‘¢|3\.|\*\*(?:Key contributions)|$))',
                    r'\*\*Methodology or strategy\*\*\s*[:ï¼š]?\s*(.*?)(?=\*\*(?:Key contributions|Limitations or challenges)|$)',
                    r'Methodology or strategy\s*[:ï¼š]\s*(.*?)(?=(?:Key contributions|Limitations or challenges)|$)',
                    # ä¸­æ–‡æ ‡é¢˜ï¼šæ–¹æ³•æˆ–ç­–ç•¥
                    r'(?:â‘¡|2\.)\s*(?:\*\*)?æ–¹æ³•æˆ–ç­–ç•¥(?:\*\*)?\s*[:ï¼š]?\s*(.*?)(?=(?:â‘¢|3\.|\*\*(?:ä¸»è¦è´¡çŒ®)|$))',
                    r'\*\*æ–¹æ³•æˆ–ç­–ç•¥\*\*\s*[:ï¼š]?\s*(.*?)(?=\*\*(?:ä¸»è¦è´¡çŒ®|æŒ‘æˆ˜æˆ–å±€é™)|$)',
                    r'æ–¹æ³•æˆ–ç­–ç•¥\s*[:ï¼š]\s*(.*?)(?=(?:ä¸»è¦è´¡çŒ®|æŒ‘æˆ˜æˆ–å±€é™)|$)'
                ],
                'contributions': [
                    # è‹±æ–‡æ ‡é¢˜ï¼šKey contributions
                    r'(?:â‘¢|3\.)\s*(?:\*\*)?Key contributions(?:\*\*)?\s*[:ï¼š]?\s*(.*?)(?=(?:â‘£|4\.|\*\*(?:Limitations or challenges)|$))',
                    r'\*\*Key contributions\*\*\s*[:ï¼š]?\s*(.*?)(?=\*\*(?:Limitations or challenges)|$)',
                    r'Key contributions\s*[:ï¼š]\s*(.*?)(?=(?:Limitations or challenges)|$)',
                    # ä¸­æ–‡æ ‡é¢˜ï¼šä¸»è¦è´¡çŒ®
                    r'(?:â‘¢|3\.)\s*(?:\*\*)?ä¸»è¦è´¡çŒ®(?:\*\*)?\s*[:ï¼š]?\s*(.*?)(?=(?:â‘£|4\.|\*\*(?:æŒ‘æˆ˜æˆ–å±€é™)|$))',
                    r'\*\*ä¸»è¦è´¡çŒ®\*\*\s*[:ï¼š]?\s*(.*?)(?=\*\*(?:æŒ‘æˆ˜æˆ–å±€é™)|$)',
                    r'ä¸»è¦è´¡çŒ®\s*[:ï¼š]\s*(.*?)(?=(?:æŒ‘æˆ˜æˆ–å±€é™)|$)'
                ],
                'challenges': [
                    # è‹±æ–‡æ ‡é¢˜ï¼šLimitations or challenges
                    r'(?:â‘£|4\.)\s*(?:\*\*)?Limitations or challenges(?:\*\*)?\s*[:ï¼š]?\s*(.*?)$',
                    r'\*\*Limitations or challenges\*\*\s*[:ï¼š]?\s*(.*?)$',
                    r'Limitations or challenges\s*[:ï¼š]\s*(.*?)$',
                    # ä¸­æ–‡æ ‡é¢˜ï¼šæŒ‘æˆ˜æˆ–å±€é™
                    r'(?:â‘£|4\.)\s*(?:\*\*)?æŒ‘æˆ˜æˆ–å±€é™(?:\*\*)?\s*[:ï¼š]?\s*(.*?)$',
                    r'\*\*æŒ‘æˆ˜æˆ–å±€é™\*\*\s*[:ï¼š]?\s*(.*?)$',
                    r'æŒ‘æˆ˜æˆ–å±€é™\s*[:ï¼š]\s*(.*?)$'
                ]
            }
            
            # ç¬¬ä¸‰æ­¥ï¼šæŒ‰å­—æ®µåŒ¹é…å†…å®¹
            
            # å¯¹æ¯ä¸ªå­—æ®µå°è¯•æ‰€æœ‰å¯èƒ½çš„åŒ¹é…æ¨¡å¼
            for field, pattern_list in patterns.items():
                for pattern in pattern_list:
                    match = re.search(pattern, cleaned_response, re.DOTALL | re.IGNORECASE)
                    if match:
                        # æå–åŒ¹é…å†…å®¹å¹¶æ¸…ç†
                        content = match.group(1).strip()
                        
                        # ç§»é™¤å¯èƒ½çš„markdownæ ¼å¼æ ‡è®°
                        content = re.sub(r'\*\*', '', content)
                        content = re.sub(r'^\s*[-*]\s*', '', content, flags=re.MULTILINE)
                        
                        # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
                        content = re.sub(r'\s+', ' ', content).strip()
                        
                        if content:  # åªæœ‰éç©ºå†…å®¹æ‰èµ‹å€¼
                            result[field] = content
                            break  # æ‰¾åˆ°åŒ¹é…åè·³å‡ºå†…å±‚å¾ªç¯
            
            # ç¬¬å››æ­¥ï¼šéªŒè¯è§£æç»“æœ
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å­—æ®µéƒ½æœ‰å†…å®¹
            empty_fields = [field for field, content in result.items() if not content.strip()]
            
            if empty_fields:
                # å¦‚æœæœ‰ç©ºå­—æ®µï¼Œå°è¯•å¤‡ç”¨è§£æç­–ç•¥
                # æŒ‰è¡Œåˆ†å‰²ï¼Œå¯»æ‰¾å¯èƒ½çš„å†…å®¹
                lines = cleaned_response.split('\n')
                current_field = None
                current_content = []
                
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„éƒ¨åˆ†æ ‡é¢˜
                    if any(keyword in line.lower() for keyword in ['motivation', 'åŠ¨æœº', 'â‘ ', '1.']):
                        if current_field and current_content:
                            result[current_field] = ' '.join(current_content).strip()
                        current_field = 'motivation'
                        current_content = []
                        # æå–æ ‡é¢˜åçš„å†…å®¹
                        title_content = re.sub(r'^.*?[:ï¼š]\s*', '', line)
                        if title_content and title_content != line:
                            current_content.append(title_content)
                    elif any(keyword in line.lower() for keyword in ['method', 'approach', 'æ–¹æ³•', 'ç­–ç•¥', 'â‘¡', '2.']):
                        if current_field and current_content:
                            result[current_field] = ' '.join(current_content).strip()
                        current_field = 'methodology'
                        current_content = []
                        title_content = re.sub(r'^.*?[:ï¼š]\s*', '', line)
                        if title_content and title_content != line:
                            current_content.append(title_content)
                    elif any(keyword in line.lower() for keyword in ['contribution', 'è´¡çŒ®', 'â‘¢', '3.']):
                        if current_field and current_content:
                            result[current_field] = ' '.join(current_content).strip()
                        current_field = 'contributions'
                        current_content = []
                        title_content = re.sub(r'^.*?[:ï¼š]\s*', '', line)
                        if title_content and title_content != line:
                            current_content.append(title_content)
                    elif any(keyword in line.lower() for keyword in ['challenge', 'limitation', 'æŒ‘æˆ˜', 'å±€é™', 'â‘£', '4.']):
                        if current_field and current_content:
                            result[current_field] = ' '.join(current_content).strip()
                        current_field = 'challenges'
                        current_content = []
                        title_content = re.sub(r'^.*?[:ï¼š]\s*', '', line)
                        if title_content and title_content != line:
                            current_content.append(title_content)
                    elif current_field:
                        # å¦‚æœå½“å‰åœ¨æŸä¸ªå­—æ®µå†…ï¼Œæ·»åŠ å†…å®¹
                        current_content.append(line)
                
                # å¤„ç†æœ€åä¸€ä¸ªå­—æ®µ
                if current_field and current_content:
                    result[current_field] = ' '.join(current_content).strip()
            
            # ç¬¬äº”æ­¥ï¼šæœ€ç»ˆéªŒè¯å’Œæ¸…ç†
            # ç¡®ä¿æ¯ä¸ªå­—æ®µéƒ½æœ‰æœ€å°é•¿åº¦çš„å†…å®¹
            for field in result:
                if not result[field] or len(result[field].strip()) < 10:
                    # å¦‚æœå†…å®¹å¤ªçŸ­æˆ–ä¸ºç©ºï¼Œæä¾›é»˜è®¤æç¤º
                    field_names = {
                        'motivation': 'ç ”ç©¶åŠ¨æœºéƒ¨åˆ†æœªèƒ½æ­£ç¡®è§£æ',
                        'methodology': 'æ–¹æ³•ç­–ç•¥éƒ¨åˆ†æœªèƒ½æ­£ç¡®è§£æ',
                        'contributions': 'ä¸»è¦è´¡çŒ®éƒ¨åˆ†æœªèƒ½æ­£ç¡®è§£æ',
                        'challenges': 'æŒ‘æˆ˜å±€é™éƒ¨åˆ†æœªèƒ½æ­£ç¡®è§£æ'
                    }
                    result[field] = field_names.get(field, f'{field}éƒ¨åˆ†æœªèƒ½æ­£ç¡®è§£æ')
            
            return result
            
        except Exception as e:
            # å¼‚å¸¸å¤„ç†ï¼šè¿”å›é”™è¯¯ä¿¡æ¯
            error_msg = f"è§£æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            return {
                'motivation': error_msg,
                'methodology': error_msg,
                'contributions': error_msg,
                'challenges': error_msg
            }
          
    def cleanup(self, file_id: str = None, thread_id: str = None):
        """
        æ¸…ç†OpenAIèµ„æº - åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶å’Œå¯¹è¯çº¿ç¨‹
        
        åŠŸèƒ½è¯´æ˜:
        1. åˆ é™¤ä¸Šä¼ åˆ°OpenAIçš„PDFæ–‡ä»¶ï¼Œé¿å…å­˜å‚¨è´¹ç”¨ç´¯ç§¯
        2. åˆ é™¤å¯¹è¯çº¿ç¨‹ï¼Œé‡Šæ”¾ä¼šè¯èµ„æºå’Œä¿æŠ¤éšç§
        3. æä¾›è¯¦ç»†çš„æ¸…ç†æ—¥å¿—å’Œå¼‚å¸¸å¤„ç†
        4. ä¸åˆ é™¤Assistantå®ä¾‹ï¼Œä¿æŒå·¥å…·å¯é‡ç”¨æ€§
        
        å‚æ•°:
            file_id (str, optional): è¦åˆ é™¤çš„OpenAIæ–‡ä»¶ID
                - é€šè¿‡upload_pdf_to_openaiå‡½æ•°è·å¾—
                - åˆ é™¤åæ— æ³•æ¢å¤ï¼Œç¡®ä¿ä¸å†éœ€è¦è¯¥æ–‡ä»¶
            thread_id (str, optional): è¦åˆ é™¤çš„å¯¹è¯çº¿ç¨‹ID
                - é€šè¿‡generate_summaryå‡½æ•°ä¸­åˆ›å»ºçš„çº¿ç¨‹è·å¾—
                - åˆ é™¤åè¯¥å¯¹è¯å†å²å°†æ°¸ä¹…ä¸¢å¤±
        
        æ¸…ç†ç­–ç•¥:
        - ä¼˜å…ˆåˆ é™¤æ–‡ä»¶ï¼ˆé¿å…å­˜å‚¨è´¹ç”¨ï¼‰
        - ç„¶ååˆ é™¤çº¿ç¨‹ï¼ˆé‡Šæ”¾ä¼šè¯èµ„æºï¼‰
        - æ¯ä¸ªåˆ é™¤æ“ä½œéƒ½æœ‰ç‹¬ç«‹çš„å¼‚å¸¸å¤„ç†
        - å³ä½¿éƒ¨åˆ†åˆ é™¤å¤±è´¥ï¼Œä¹Ÿä¼šç»§ç»­å°è¯•å…¶ä»–èµ„æº
        - è®°å½•è¯¦ç»†çš„æ“ä½œæ—¥å¿—ä¾¿äºè°ƒè¯•
        
        æ³¨æ„äº‹é¡¹:
        - åˆ é™¤æ“ä½œä¸å¯é€†ï¼Œè¯·ç¡®ä¿èµ„æºä¸å†éœ€è¦
        - ç½‘ç»œå¼‚å¸¸å¯èƒ½å¯¼è‡´åˆ é™¤å¤±è´¥ï¼Œå»ºè®®é‡è¯•
        - Assistantå®ä¾‹ä¼šä¿ç•™ï¼Œå¯ç»§ç»­ç”¨äºåç»­å¤„ç†
        """
        cleanup_results = []  # è®°å½•æ¸…ç†æ“ä½œç»“æœ
        
        # ===========================================
        # 1. åˆ é™¤ä¸Šä¼ çš„PDFæ–‡ä»¶
        # ===========================================
        if file_id:
            try:
                if self.log_queue:
                    self.log_queue.put(f"å¼€å§‹åˆ é™¤OpenAIæ–‡ä»¶: {file_id}")
                
                # ç¡®ä¿å®¢æˆ·ç«¯å·²åˆå§‹åŒ–
                if not self.client:
                    if self.log_queue:
                        self.log_queue.put("è­¦å‘Š: OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡æ–‡ä»¶åˆ é™¤")
                    cleanup_results.append(f"æ–‡ä»¶åˆ é™¤è·³è¿‡: å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                else:
                    # è°ƒç”¨OpenAI APIåˆ é™¤æ–‡ä»¶
                    # ä½¿ç”¨client.files.delete()æ–¹æ³•åˆ é™¤æŒ‡å®šæ–‡ä»¶
                    delete_response = self.client.files.delete(file_id)
                    
                    if delete_response.deleted:
                        if self.log_queue:
                            self.log_queue.put(f"æˆåŠŸåˆ é™¤OpenAIæ–‡ä»¶: {file_id}")
                        cleanup_results.append(f"æ–‡ä»¶åˆ é™¤æˆåŠŸ: {file_id}")
                    else:
                        if self.log_queue:
                            self.log_queue.put(f"æ–‡ä»¶åˆ é™¤å¤±è´¥: {file_id} - APIè¿”å›deleted=False")
                        cleanup_results.append(f"æ–‡ä»¶åˆ é™¤å¤±è´¥: {file_id}")
                        
            except openai.NotFoundError:
                # æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤
                if self.log_queue:
                    self.log_queue.put(f"æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²åˆ é™¤: {file_id}")
                cleanup_results.append(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_id}")
                
            except openai.AuthenticationError:
                # APIå¯†é’¥è®¤è¯å¤±è´¥
                if self.log_queue:
                    self.log_queue.put(f"APIè®¤è¯å¤±è´¥ï¼Œæ— æ³•åˆ é™¤æ–‡ä»¶: {file_id}")
                cleanup_results.append(f"æ–‡ä»¶åˆ é™¤å¤±è´¥: APIè®¤è¯é”™è¯¯")
                
            except openai.RateLimitError:
                # APIè°ƒç”¨é¢‘ç‡é™åˆ¶
                if self.log_queue:
                    self.log_queue.put(f"APIè°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œæ–‡ä»¶åˆ é™¤å¤±è´¥: {file_id}")
                cleanup_results.append(f"æ–‡ä»¶åˆ é™¤å¤±è´¥: APIé¢‘ç‡é™åˆ¶")
                
            except openai.APIError as e:
                # å…¶ä»–OpenAI APIé”™è¯¯
                if self.log_queue:
                    self.log_queue.put(f"OpenAI APIé”™è¯¯ï¼Œæ–‡ä»¶åˆ é™¤å¤±è´¥: {file_id} - {str(e)}")
                cleanup_results.append(f"æ–‡ä»¶åˆ é™¤å¤±è´¥: APIé”™è¯¯ - {str(e)}")
                
            except Exception as e:
                # å…¶ä»–æœªé¢„æœŸçš„é”™è¯¯
                if self.log_queue:
                    self.log_queue.put(f"æ–‡ä»¶åˆ é™¤å‘ç”ŸæœªçŸ¥é”™è¯¯: {file_id} - {str(e)}")
                cleanup_results.append(f"æ–‡ä»¶åˆ é™¤å¤±è´¥: æœªçŸ¥é”™è¯¯ - {str(e)}")
        
        # ===========================================
        # 2. åˆ é™¤å¯¹è¯çº¿ç¨‹
        # ===========================================
        if thread_id:
            try:
                if self.log_queue:
                    self.log_queue.put(f"å¼€å§‹åˆ é™¤å¯¹è¯çº¿ç¨‹: {thread_id}")
                
                # ç¡®ä¿å®¢æˆ·ç«¯å·²åˆå§‹åŒ–
                if not self.client:
                    if self.log_queue:
                        self.log_queue.put("è­¦å‘Š: OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè·³è¿‡çº¿ç¨‹åˆ é™¤")
                    cleanup_results.append(f"çº¿ç¨‹åˆ é™¤è·³è¿‡: å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                else:
                    # è°ƒç”¨OpenAI APIåˆ é™¤çº¿ç¨‹
                    # ä½¿ç”¨client.beta.threads.delete()æ–¹æ³•åˆ é™¤æŒ‡å®šçº¿ç¨‹
                    delete_response = self.client.beta.threads.delete(thread_id)
                    
                    if delete_response.deleted:
                        if self.log_queue:
                            self.log_queue.put(f"æˆåŠŸåˆ é™¤å¯¹è¯çº¿ç¨‹: {thread_id}")
                        cleanup_results.append(f"çº¿ç¨‹åˆ é™¤æˆåŠŸ: {thread_id}")
                    else:
                        if self.log_queue:
                            self.log_queue.put(f"çº¿ç¨‹åˆ é™¤å¤±è´¥: {thread_id} - APIè¿”å›deleted=False")
                        cleanup_results.append(f"çº¿ç¨‹åˆ é™¤å¤±è´¥: {thread_id}")
                        
            except openai.NotFoundError:
                # çº¿ç¨‹ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤
                if self.log_queue:
                    self.log_queue.put(f"çº¿ç¨‹ä¸å­˜åœ¨æˆ–å·²åˆ é™¤: {thread_id}")
                cleanup_results.append(f"çº¿ç¨‹ä¸å­˜åœ¨: {thread_id}")
                
            except openai.AuthenticationError:
                # APIå¯†é’¥è®¤è¯å¤±è´¥
                if self.log_queue:
                    self.log_queue.put(f"APIè®¤è¯å¤±è´¥ï¼Œæ— æ³•åˆ é™¤çº¿ç¨‹: {thread_id}")
                cleanup_results.append(f"çº¿ç¨‹åˆ é™¤å¤±è´¥: APIè®¤è¯é”™è¯¯")
                
            except openai.RateLimitError:
                # APIè°ƒç”¨é¢‘ç‡é™åˆ¶
                if self.log_queue:
                    self.log_queue.put(f"APIè°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œçº¿ç¨‹åˆ é™¤å¤±è´¥: {thread_id}")
                cleanup_results.append(f"çº¿ç¨‹åˆ é™¤å¤±è´¥: APIé¢‘ç‡é™åˆ¶")
                
            except openai.APIError as e:
                # å…¶ä»–OpenAI APIé”™è¯¯
                if self.log_queue:
                    self.log_queue.put(f"OpenAI APIé”™è¯¯ï¼Œçº¿ç¨‹åˆ é™¤å¤±è´¥: {thread_id} - {str(e)}")
                cleanup_results.append(f"çº¿ç¨‹åˆ é™¤å¤±è´¥: APIé”™è¯¯ - {str(e)}")
                
            except Exception as e:
                # å…¶ä»–æœªé¢„æœŸçš„é”™è¯¯
                if self.log_queue:
                    self.log_queue.put(f"çº¿ç¨‹åˆ é™¤å‘ç”ŸæœªçŸ¥é”™è¯¯: {thread_id} - {str(e)}")
                cleanup_results.append(f"çº¿ç¨‹åˆ é™¤å¤±è´¥: æœªçŸ¥é”™è¯¯ - {str(e)}")
        
        # ===========================================
        # 3. æ€»ç»“æ¸…ç†æ“ä½œç»“æœ
        # ===========================================
        if cleanup_results:
            if self.log_queue:
                self.log_queue.put(f"èµ„æºæ¸…ç†å®Œæˆï¼Œæ“ä½œç»“æœ: {'; '.join(cleanup_results)}")
        else:
            if self.log_queue:
                self.log_queue.put("æœªæä¾›éœ€è¦æ¸…ç†çš„èµ„æºIDï¼Œè·³è¿‡æ¸…ç†æ“ä½œ")
        
        # è¿”å›æ¸…ç†ç»“æœä¾›è°ƒç”¨è€…å‚è€ƒ
        return {
            'cleanup_performed': len(cleanup_results) > 0,
            'results': cleanup_results,
            'file_cleaned': file_id is not None,
            'thread_cleaned': thread_id is not None
        }
    
    def _handle_api_error(self, error: Exception, operation: str) -> Dict[str, Any]:
        """
        å¤„ç†OpenAI APIè°ƒç”¨é”™è¯¯
        
        åŠŸèƒ½è¯´æ˜:
        1. åˆ†æä¸åŒç±»å‹çš„APIé”™è¯¯
        2. æä¾›ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        3. å†³å®šæ˜¯å¦éœ€è¦é‡è¯•
        4. è®°å½•è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
        
        å‚æ•°:
            error (Exception): æ•è·çš„å¼‚å¸¸å¯¹è±¡
            operation (str): å‘ç”Ÿé”™è¯¯çš„æ“ä½œåç§°
        
        è¿”å›:
            Dict[str, Any]: æ ‡å‡†åŒ–çš„é”™è¯¯å“åº”
        
        é”™è¯¯ç±»å‹å¤„ç†:
        - ç½‘ç»œè¿æ¥é”™è¯¯: å»ºè®®é‡è¯•
        - APIå¯†é’¥é”™è¯¯: æç¤ºæ£€æŸ¥å¯†é’¥
        - é…é¢ä¸è¶³: æç¤ºå‡çº§è´¦æˆ·
        - æ–‡ä»¶æ ¼å¼é”™è¯¯: æç¤ºæ£€æŸ¥æ–‡ä»¶
        """
        # TODO: å®ç°é”™è¯¯å¤„ç†é€»è¾‘
        # 1. è¯†åˆ«ä¸åŒç±»å‹çš„OpenAI APIé”™è¯¯
        # 2. ç”Ÿæˆç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
        # 3. å†³å®šé‡è¯•ç­–ç•¥
        # 4. è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        # 5. è¿”å›æ ‡å‡†åŒ–çš„é”™è¯¯å“åº”æ ¼å¼
        pass